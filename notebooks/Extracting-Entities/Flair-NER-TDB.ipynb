{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7c3628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding project dir to path: /Users/marijnkoolen/Code/Huygens/republic-project\n"
     ]
    }
   ],
   "source": [
    "# This reload library is just used for developing the REPUBLIC hOCR parser \n",
    "# and can be removed once this module is stable.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# This is needed to add the repo dir to the path so jupyter\n",
    "# can load the republic modules directly from the notebooks\n",
    "import os\n",
    "import sys\n",
    "repo_name = 'republic-project'\n",
    "repo_dir = os.path.split(os.getcwd())[0].split(repo_name)[0] + repo_name\n",
    "print(\"adding project dir to path:\", repo_dir)\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path = [repo_dir] + sys.path\n",
    "else:\n",
    "    sys.path.remove(repo_dir)\n",
    "    sys.path = [repo_dir] + sys.path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47bea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, CharLMEmbeddings, FlairEmbeddings\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed4265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:02:45,147 Reading data from /Users/marijnkoolen/Code/Huygens/republic-project/ground_truth/entities/tag_de_besluiten/flair_training_single_layer\n",
      "2023-04-25 16:02:45,147 Train: /Users/marijnkoolen/Code/Huygens/republic-project/ground_truth/entities/tag_de_besluiten/flair_training_single_layer/train_1.0.txt\n",
      "2023-04-25 16:02:45,148 Dev: /Users/marijnkoolen/Code/Huygens/republic-project/ground_truth/entities/tag_de_besluiten/flair_training_single_layer/validate.txt\n",
      "2023-04-25 16:02:45,148 Test: /Users/marijnkoolen/Code/Huygens/republic-project/ground_truth/entities/tag_de_besluiten/flair_training_single_layer/test.txt\n",
      "Corpus: 1330 train + 154 dev + 147 test sentences\n",
      "2023-04-25 16:02:47,370 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1330it [00:00, 36745.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:02:47,419 Dictionary created for label 'ner' with 9 values: HOE (seen 5017 times), LOC (seen 4584 times), PER (seen 3188 times), ORG (seen 2466 times), DAT (seen 2218 times), RES (seen 489 times), COM (seen 287 times), NAM (seen 237 times)\n",
      "Dictionary with 9 tags: <unk>, HOE, LOC, PER, ORG, DAT, RES, COM, NAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:02:49,400 SequenceTagger predicts: Dictionary with 33 tags: O, S-HOE, B-HOE, E-HOE, I-HOE, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-DAT, B-DAT, E-DAT, I-DAT, S-RES, B-RES, E-RES, I-RES, S-COM, B-COM, E-COM, I-COM, S-NAM, B-NAM, E-NAM, I-NAM\n",
      "2023-04-25 16:02:49,405 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-25 16:02:49,405 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(138, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(138, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=35, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2023-04-25 16:02:49,405 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-25 16:02:49,406 Corpus: \"Corpus: 1330 train + 154 dev + 147 test sentences\"\n",
      "2023-04-25 16:02:49,406 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-25 16:02:49,407 Parameters:\n",
      "2023-04-25 16:02:49,407  - learning_rate: \"0.050000\"\n",
      "2023-04-25 16:02:49,407  - mini_batch_size: \"32\"\n",
      "2023-04-25 16:02:49,407  - patience: \"3\"\n",
      "2023-04-25 16:02:49,408  - anneal_factor: \"0.5\"\n",
      "2023-04-25 16:02:49,408  - max_epochs: \"10\"\n",
      "2023-04-25 16:02:49,408  - shuffle: \"True\"\n",
      "2023-04-25 16:02:49,409  - train_with_dev: \"False\"\n",
      "2023-04-25 16:02:49,409  - batch_growth_annealing: \"False\"\n",
      "2023-04-25 16:02:49,410 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-25 16:02:49,410 Model training base path: \"/Users/marijnkoolen/Code/Huygens/republic-project/data/embeddings/flair_embeddings/resources/taggers/ner-tbd-single_layer-train_1.0-2023-04-25\"\n",
      "2023-04-25 16:02:49,410 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-25 16:02:49,411 Device: cpu\n",
      "2023-04-25 16:02:49,411 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-25 16:02:49,411 Embeddings storage mode: cpu\n",
      "2023-04-25 16:02:49,412 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-25 16:05:47,684 epoch 1 - iter 4/42 - loss 3.36476628 - time (sec): 178.27 - samples/sec: 168.10 - lr: 0.050000\n",
      "2023-04-25 16:07:43,727 epoch 1 - iter 8/42 - loss 2.70421668 - time (sec): 294.32 - samples/sec: 187.90 - lr: 0.050000\n"
     ]
    }
   ],
   "source": [
    "flair_dir = f'{repo_dir}/data/embeddings/flair_embeddings/'\n",
    "\n",
    "# 1. get the corpus\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "layer_name = 'HOE'\n",
    "layer_name = 'single_layer'\n",
    "train_size = 1.0\n",
    "data_folder = f'{repo_dir}/ground_truth/entities/tag_de_besluiten/flair_training_{layer_name}'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file=f'train_{train_size}.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='validate.txt')\n",
    "\n",
    "print(corpus)\n",
    "\n",
    "# 2. what label do we want to predict?\n",
    "label_type = 'ner'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "print(label_dict)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "gysbert_embeddings = TransformerWordEmbeddings('emanjavacas/GysBERT',\n",
    "                                               layers=\"-1\",\n",
    "                                               allow_long_sentences=False,\n",
    "                                               model_max_length=512)\n",
    "embedding_types = [\n",
    "    FlairEmbeddings(f'{flair_dir}/resources/taggers/language_model_bw_char/best-lm.pt'),\n",
    "    FlairEmbeddings(f'{flair_dir}/resources/taggers/language_model_fw_char/best-lm.pt'),\n",
    "    #WordEmbeddings(''),\n",
    "    # CharacterEmbeddings(),\n",
    "]\n",
    "\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "model_dir = f'{flair_dir}/resources/taggers/ner-tbd-{layer_name}-train_{train_size}-{datetime.date.today().isoformat()}'\n",
    "# 7. start training\n",
    "trainer.train(model_dir,\n",
    "              learning_rate=0.05,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e01dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, CharLMEmbeddings, FlairEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "import flair\n",
    "\n",
    "\n",
    "flair.device = torch.device('mps')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da06b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_dir = f'{repo_dir}/data/embeddings/flair_embeddings/'\n",
    "\n",
    "# 1. get the corpus\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "layer_name = 'single_layer'\n",
    "data_folder = f'{repo_dir}/ground_truth/entities/tag_de_besluiten/flair_training_{layer_name}'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='validate.txt')\n",
    "\n",
    "print(corpus)\n",
    "\n",
    "# 2. what label do we want to predict?\n",
    "label_type = 'ner'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "print(label_dict)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "    FlairEmbeddings(f'{flair_dir}/resources/taggers/language_model_bw_char/best-lm.pt'),\n",
    "    FlairEmbeddings(f'{flair_dir}/resources/taggers/language_model_fw_char/best-lm.pt'),\n",
    "    #WordEmbeddings(''),\n",
    "    # CharacterEmbeddings(),\n",
    "]\n",
    "\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=True).to(device)\n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "model_dir = f'{flair_dir}/resources/taggers/ner-tbd-{layer_name}-{datetime.date.today().isoformat()}'\n",
    "# 7. start training\n",
    "trainer.train(model_dir,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              embeddings_storage_mode='mps',\n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install flair --upgrade"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
