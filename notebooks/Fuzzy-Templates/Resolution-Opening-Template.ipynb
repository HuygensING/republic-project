{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marijnkoolen/Code/Huygens/republic-project\n"
     ]
    }
   ],
   "source": [
    "# This reload library is just used for developing the REPUBLIC hOCR parser \n",
    "# and can be removed once this module is stable.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# This is needed to add the repo dir to the path so jupyter\n",
    "# can load the republic modules directly from the notebooks\n",
    "import os\n",
    "import sys\n",
    "repo_name = 'republic-project'\n",
    "repo_dir = os.path.split(os.getcwd())[0].split(repo_name)[0] + repo_name\n",
    "print(repo_dir)\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.append(repo_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_search.fuzzy_template_searcher import FuzzyTemplateSearcher, FuzzyTemplate\n",
    "\n",
    "from republic.model.resolution_phrase_model import resolution_phrase_sets as rps\n",
    "from republic.model.resolution_templates import opening_templates\n",
    "from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "\n",
    "\n",
    "searcher_config = {\n",
    "    \"char_match_threshold\": 0.7,\n",
    "    \"ngram_threshold\": 0.5,\n",
    "    \"levenshtein_threshold\": 0.7,\n",
    "    \"max_length_variance\": 3,\n",
    "    \"include_variants\": True,\n",
    "    \"filter_distractors\": True,\n",
    "    \"ngram_size\": 2,\n",
    "    \"skip_size\": 2,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proposition_from_correspondence',\n",
       " 'proposition_from_statement',\n",
       " 'proposition_short_request',\n",
       " 'proposition_representatives']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t['label'] for t in opening_templates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"label\": \"proposition_from_correspondence\",\n",
      "    \"ordered\": true,\n",
      "    \"type\": \"group\",\n",
      "    \"elements\": [\n",
      "        {\n",
      "            \"label\": \"formula\",\n",
      "            \"type\": \"group\",\n",
      "            \"elements\": [\n",
      "                {\n",
      "                    \"label\": \"proposition_opening\",\n",
      "                    \"required\": true\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"label\": \"proposer\",\n",
      "            \"type\": \"group\",\n",
      "            \"ordered\": false,\n",
      "            \"elements\": [\n",
      "                {\n",
      "                    \"label\": \"person_name_prefix\",\n",
      "                    \"required\": false,\n",
      "                    \"cardinality\": \"multi\"\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"title\",\n",
      "                    \"required\": false,\n",
      "                    \"cardinality\": \"multi\"\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"proposer_name\",\n",
      "                    \"required\": false,\n",
      "                    \"variable\": true\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"person_role\",\n",
      "                    \"required\": false,\n",
      "                    \"cardinality\": \"multi\"\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"representation_relation\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"affairs_relation\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"resolution_relation\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"location_relation\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"location\",\n",
      "                    \"required\": false,\n",
      "                    \"variable\": true\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"organisation\",\n",
      "                    \"required\": false\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"label\": \"proposition_origin\",\n",
      "            \"type\": \"group\",\n",
      "            \"ordered\": true,\n",
      "            \"elements\": [\n",
      "                {\n",
      "                    \"label\": \"correspondence_from\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"residence_relation\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"person_location\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"location_relation\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"location\",\n",
      "                    \"required\": false,\n",
      "                    \"variable\": true\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"temporal_reference\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"addressed_to\",\n",
      "                    \"required\": false\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"person_name_prefix\",\n",
      "                    \"required\": false,\n",
      "                    \"cardinality\": \"multi\"\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"person_role\",\n",
      "                    \"required\": false,\n",
      "                    \"cardinality\": \"multi\"\n",
      "                },\n",
      "                {\n",
      "                    \"label\": \"addressee_name\",\n",
      "                    \"required\": false,\n",
      "                    \"variable\": true\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"label\": \"proposition_verb\",\n",
      "            \"type\": \"group\",\n",
      "            \"elements\": [\n",
      "                {\n",
      "                    \"label\": \"proposition_verb\",\n",
      "                    \"required\": false\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(opening_templates[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['proposition_opening_phrases', 'proposition_reason_phrases', 'proposition_closing_phrases', 'proposition_from_phrases', 'proposition_verbs', 'decision_phrases', 'resolution_link_phrases', 'prefix_phrases', 'organisation_phrases', 'location_phrases', 'esteem_titles', 'person_role_phrases', 'military_phrases', 'misc', 'provinces'])\n",
      "{'phrase': 'haar Hoog Mogende', 'label': ['title', 'organisation_title'], 'variants': ['haar Hoog Mog.', 'haar Ho. Mo.']}\n"
     ]
    }
   ],
   "source": [
    "print(rps.keys())\n",
    "opening_set_names = [\n",
    "    'proposition_opening_phrases', 'person_role_phrases', 'proposition_from_phrases', 'proposition_verbs',\n",
    "    'esteem_titles', 'misc', 'provinces', 'prefix_phrases', 'resolution_link_phrases',\n",
    "    'location_phrases', 'organisation_phrases', 'misc', \n",
    "]\n",
    "phrases = [phrase for set_name in opening_set_names for phrase in rps[set_name]]\n",
    "\n",
    "for phrase in phrases:\n",
    "    if 'Mogende' in phrase['phrase']:\n",
    "        print(phrase)\n",
    "phrase_model = PhraseModel(model=phrases)\n",
    "opening_template = FuzzyTemplate(phrase_model, opening_templates[0])\n",
    "\n",
    "opening_searcher = FuzzyTemplateSearcher(opening_template, searcher_config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from republic.elastic.republic_elasticsearch import initialize_es\n",
    "from republic.config.republic_config import set_config_inventory_num\n",
    "\n",
    "rep_es = initialize_es(host_type=\"external\")\n",
    "\n",
    "inv_num = 3793\n",
    "inv_config = set_config_inventory_num(inv_num, ocr_type=\"pagexml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from republic.extraction.extract_resolution_metadata import skip_resolution, add_resolution_metadata\n",
    "from republic.extraction.extract_resolution_metadata import VariableMatcher\n",
    "\n",
    "\n",
    "skip_formulas = {\n",
    "    'heeft aan haar Hoog Mog. voorgedragen',\n",
    "    'heeft ter Vergadering gecommuniceert ',\n",
    "    'ZYnde ter Vergaderinge geëxhibeert vier Pasporten van',\n",
    "    'hebben ter Vergaderinge ingebraght',\n",
    "    'hebben ter Vergaderinge voorgedragen'\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from republic.elastic.republic_elasticsearch import initialize_es\n",
    "from republic.config.republic_config import set_config_inventory_num\n",
    "\n",
    "rep_es = initialize_es(host_type=\"external\")\n",
    "\n",
    "inv_num = 3793\n",
    "\n",
    "query = {\n",
    "    'query': {\n",
    "        'match': {\n",
    "            'metadata.inventory_num': inv_num,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "resolutions = rep_es.retrieve_resolutions_by_query(query)\n",
    "len(resolutions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONtfangen een Missive van\n",
      "\t['proposition_opening', 'proposition_from_correspondence', 'proposition_type:missive']\n",
      "Missive\n",
      "\t['document', 'document_type:missive']\n",
      "den Heere\n",
      "\tperson_name_prefix\n",
      "haar Hoog Mogende\n",
      "\t['title', 'organisation_title']\n",
      "Minister\n",
      "\t['person_role', 'domain:politics', 'minister', 'representative']\n",
      "by den Ryksdag\n",
      "\t['organisation', 'german', 'political']\n",
      "geschreeven te\n",
      "\tcorrespondence_from\n",
      "Regensburgh\n",
      "\t['location', 'region']\n",
      "Dresden\n",
      "\t['location', 'region']\n",
      "houdende advertentie.\n",
      "\t['proposition_verb', 'proposition_opening_end_verb', 'proposition_body']\n",
      "houdende\n",
      "\t['proposition_verb', 'proposition_opening_end_verb', 'proposition_body']\n",
      "WAAR op geen resolutie is gevallen.\n",
      "\t['no_decision', 'resolution_decision']\n",
      "Resolutie\n",
      "\t['resolution_relation', 'resolution']\n"
     ]
    }
   ],
   "source": [
    "para_id = 'session-1750-07-13-num-1-para-3'\n",
    "query = {\n",
    "    'match': {\n",
    "        'text_id.keyword': para_id\n",
    "    }\n",
    "}\n",
    "response = rep_es.es_anno.search(index='phrase_matches', query=query, size=100)\n",
    "\n",
    "matches = [hit['_source'] for hit in response['hits']['hits']]\n",
    "for match in matches:\n",
    "    print(f\"{match['phrase']}\\n\\t{match['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'offset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mopening_searcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_template_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Huygens/fuzzy-search/fuzzy_search/fuzzy_template_searcher.py:541\u001b[0m, in \u001b[0;36mFuzzyTemplateSearcher.find_template_matches\u001b[0;34m(self, phrase_matches)\u001b[0m\n\u001b[1;32m    539\u001b[0m template_matches: List[TemplateMatch] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# make sure the matches are sorted in order of occurrence in the text\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m template_phrase_matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_phrase_matches(\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mphrase_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    542\u001b[0m sequence_start_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# print(\"num matches:\", len(template_phrase_matches))\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# for phrase_match in template_phrase_matches:\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m#     print(\"\\t\", phrase_match.label, phrase_match.phrase.phrase_string, \"\\t\", phrase_match.string)\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/Huygens/fuzzy-search/fuzzy_search/fuzzy_template_searcher.py:541\u001b[0m, in \u001b[0;36mFuzzyTemplateSearcher.find_template_matches.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    539\u001b[0m template_matches: List[TemplateMatch] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# make sure the matches are sorted in order of occurrence in the text\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m template_phrase_matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_phrase_matches(\u001b[38;5;28msorted\u001b[39m(phrase_matches, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m))\n\u001b[1;32m    542\u001b[0m sequence_start_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# print(\"num matches:\", len(template_phrase_matches))\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# for phrase_match in template_phrase_matches:\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m#     print(\"\\t\", phrase_match.label, phrase_match.phrase.phrase_string, \"\\t\", phrase_match.string)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'offset'"
     ]
    }
   ],
   "source": [
    "opening_searcher.find_template_matches(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Phrase Match Labels in Phrase Match Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to do: 514989\n",
      "to do: 513989\n",
      "to do: 512989\n",
      "to do: 511989\n",
      "to do: 510989\n",
      "to do: 509989\n",
      "to do: 508989\n",
      "to do: 507989\n",
      "to do: 506989\n",
      "to do: 505989\n",
      "to do: 504989\n",
      "to do: 503989\n",
      "to do: 502989\n",
      "to do: 501989\n",
      "to do: 500989\n",
      "to do: 499989\n",
      "to do: 498989\n",
      "to do: 497989\n",
      "to do: 496989\n",
      "to do: 495989\n",
      "to do: 494989\n",
      "to do: 493989\n",
      "to do: 492989\n",
      "to do: 491989\n",
      "to do: 490989\n",
      "to do: 489989\n",
      "to do: 488989\n",
      "to do: 487989\n",
      "to do: 486989\n",
      "to do: 485989\n",
      "to do: 484989\n",
      "to do: 483989\n",
      "to do: 482989\n",
      "to do: 481989\n",
      "to do: 480989\n",
      "to do: 479989\n",
      "to do: 478989\n",
      "to do: 477989\n",
      "to do: 476989\n",
      "to do: 475989\n",
      "to do: 474989\n",
      "to do: 473989\n",
      "to do: 472989\n",
      "to do: 471989\n",
      "to do: 470989\n",
      "to do: 469989\n",
      "to do: 468989\n",
      "to do: 467989\n",
      "to do: 466989\n",
      "to do: 465989\n",
      "to do: 464989\n",
      "to do: 463989\n",
      "to do: 462989\n",
      "to do: 461989\n",
      "to do: 460989\n",
      "to do: 459989\n",
      "to do: 458989\n",
      "to do: 457989\n",
      "to do: 456989\n",
      "to do: 455989\n",
      "to do: 454989\n",
      "to do: 453989\n",
      "to do: 452989\n",
      "to do: 451989\n",
      "to do: 450989\n",
      "to do: 449989\n",
      "to do: 448989\n",
      "to do: 447989\n",
      "to do: 446989\n",
      "to do: 445989\n",
      "to do: 444989\n",
      "to do: 443989\n",
      "to do: 442989\n",
      "to do: 441989\n",
      "to do: 440989\n",
      "to do: 439989\n",
      "to do: 438989\n",
      "to do: 437989\n",
      "to do: 436989\n",
      "to do: 435989\n",
      "to do: 434989\n",
      "to do: 433989\n",
      "to do: 432989\n",
      "to do: 431989\n",
      "to do: 430989\n",
      "to do: 429989\n",
      "to do: 428989\n",
      "to do: 427989\n",
      "to do: 426989\n",
      "to do: 425989\n",
      "to do: 424989\n",
      "to do: 423989\n",
      "to do: 422989\n",
      "to do: 421989\n",
      "to do: 420989\n",
      "to do: 419989\n",
      "to do: 418989\n",
      "to do: 417989\n",
      "to do: 416989\n",
      "to do: 415989\n",
      "to do: 414989\n",
      "to do: 413989\n",
      "to do: 412989\n",
      "to do: 411989\n",
      "to do: 410989\n",
      "to do: 409989\n",
      "to do: 408989\n",
      "to do: 407989\n",
      "to do: 406989\n",
      "to do: 405989\n",
      "to do: 404989\n",
      "to do: 403989\n",
      "to do: 402989\n",
      "to do: 401989\n",
      "to do: 400989\n",
      "to do: 399989\n",
      "to do: 398989\n",
      "to do: 397989\n",
      "to do: 396989\n",
      "to do: 395989\n",
      "to do: 394989\n",
      "to do: 393989\n",
      "to do: 392989\n",
      "to do: 391989\n",
      "to do: 390989\n",
      "to do: 389989\n",
      "to do: 388989\n",
      "to do: 387989\n",
      "to do: 386989\n",
      "to do: 385989\n",
      "to do: 384989\n",
      "to do: 383989\n",
      "to do: 382989\n",
      "to do: 381989\n",
      "to do: 380989\n",
      "to do: 379989\n",
      "to do: 378989\n",
      "to do: 377989\n",
      "to do: 376989\n",
      "to do: 375989\n",
      "to do: 374989\n",
      "to do: 373989\n",
      "to do: 372989\n",
      "to do: 371989\n",
      "to do: 370989\n",
      "to do: 369989\n",
      "to do: 368989\n",
      "to do: 367989\n",
      "to do: 366989\n",
      "to do: 365989\n",
      "to do: 364989\n",
      "to do: 363989\n",
      "to do: 362989\n",
      "to do: 361989\n",
      "to do: 360989\n",
      "to do: 359989\n",
      "to do: 358989\n",
      "to do: 357989\n",
      "to do: 356989\n",
      "to do: 355989\n",
      "to do: 354989\n",
      "to do: 353989\n",
      "to do: 352989\n",
      "to do: 351989\n",
      "to do: 350989\n",
      "to do: 349989\n",
      "to do: 348989\n",
      "to do: 347989\n",
      "to do: 346989\n",
      "to do: 345989\n",
      "to do: 344989\n",
      "to do: 343989\n",
      "to do: 342989\n",
      "to do: 341989\n",
      "to do: 340989\n",
      "to do: 339989\n",
      "to do: 338989\n",
      "to do: 337989\n",
      "to do: 336989\n",
      "to do: 335989\n",
      "to do: 334989\n",
      "to do: 333989\n",
      "to do: 332989\n",
      "to do: 331989\n",
      "to do: 330989\n",
      "to do: 329989\n",
      "to do: 328989\n",
      "to do: 327989\n",
      "to do: 326989\n",
      "to do: 325989\n",
      "to do: 324989\n",
      "to do: 323989\n",
      "to do: 322989\n",
      "to do: 321989\n",
      "to do: 320989\n",
      "to do: 319989\n",
      "to do: 318989\n",
      "to do: 317989\n",
      "to do: 316989\n",
      "to do: 315989\n",
      "to do: 314989\n",
      "to do: 313989\n",
      "to do: 312989\n",
      "to do: 311989\n",
      "to do: 310989\n",
      "to do: 309989\n",
      "to do: 308989\n",
      "to do: 307989\n",
      "to do: 306989\n",
      "to do: 305989\n",
      "to do: 304989\n",
      "to do: 303989\n",
      "to do: 302989\n",
      "to do: 301989\n",
      "to do: 300989\n",
      "to do: 299989\n",
      "to do: 298989\n",
      "to do: 297989\n",
      "to do: 296989\n",
      "to do: 295989\n",
      "to do: 294989\n",
      "to do: 293989\n",
      "to do: 292989\n",
      "to do: 291989\n",
      "to do: 290989\n",
      "to do: 289989\n",
      "to do: 288989\n",
      "to do: 287989\n",
      "to do: 286989\n",
      "to do: 285989\n",
      "to do: 284989\n",
      "to do: 283989\n",
      "to do: 282989\n",
      "to do: 281989\n",
      "to do: 280989\n",
      "to do: 279989\n",
      "to do: 278989\n",
      "to do: 277989\n",
      "to do: 276989\n",
      "to do: 275989\n",
      "to do: 274989\n",
      "to do: 273989\n",
      "to do: 272989\n",
      "to do: 271989\n",
      "to do: 270989\n",
      "to do: 269989\n",
      "to do: 268989\n",
      "to do: 267989\n",
      "to do: 266989\n",
      "to do: 265989\n",
      "to do: 264989\n",
      "to do: 263989\n",
      "to do: 262989\n",
      "to do: 261989\n",
      "to do: 260989\n",
      "to do: 259989\n",
      "to do: 258989\n",
      "to do: 257989\n",
      "to do: 256989\n",
      "to do: 255989\n",
      "to do: 254989\n",
      "to do: 253989\n",
      "to do: 252989\n",
      "to do: 251989\n",
      "to do: 250989\n",
      "to do: 249989\n",
      "to do: 248989\n",
      "to do: 247989\n",
      "to do: 246989\n",
      "to do: 245989\n",
      "to do: 244989\n",
      "to do: 243989\n",
      "to do: 242989\n",
      "to do: 241989\n",
      "to do: 240989\n",
      "to do: 239989\n",
      "to do: 238989\n",
      "to do: 237989\n",
      "to do: 236989\n",
      "to do: 235989\n",
      "to do: 234989\n",
      "to do: 233989\n",
      "to do: 232989\n",
      "to do: 231989\n",
      "to do: 230989\n",
      "to do: 229989\n",
      "to do: 228989\n",
      "to do: 227989\n",
      "to do: 226989\n",
      "to do: 225989\n",
      "to do: 224989\n",
      "to do: 223989\n",
      "to do: 222989\n",
      "to do: 221989\n",
      "to do: 220989\n",
      "to do: 219989\n",
      "to do: 218989\n",
      "to do: 217989\n",
      "to do: 216989\n",
      "to do: 215989\n",
      "to do: 214989\n",
      "to do: 213989\n",
      "to do: 212989\n",
      "to do: 211989\n",
      "to do: 210989\n",
      "to do: 209989\n",
      "to do: 208989\n",
      "to do: 207989\n",
      "to do: 206989\n",
      "to do: 205989\n",
      "to do: 204989\n",
      "to do: 203989\n",
      "to do: 202989\n",
      "to do: 201989\n",
      "to do: 200989\n",
      "to do: 199989\n",
      "to do: 198989\n",
      "to do: 197989\n",
      "to do: 196989\n",
      "to do: 195989\n",
      "to do: 194989\n",
      "to do: 193989\n",
      "to do: 192989\n",
      "to do: 191989\n",
      "to do: 190989\n",
      "to do: 189989\n",
      "to do: 188989\n",
      "to do: 187989\n",
      "to do: 186989\n",
      "to do: 185989\n",
      "to do: 184989\n",
      "to do: 183989\n",
      "to do: 182989\n",
      "to do: 181989\n",
      "to do: 180989\n",
      "to do: 179989\n",
      "to do: 178989\n",
      "to do: 177989\n",
      "to do: 176989\n",
      "to do: 175989\n",
      "to do: 174989\n",
      "to do: 173989\n",
      "to do: 172989\n",
      "to do: 171989\n",
      "to do: 170989\n",
      "to do: 169989\n",
      "to do: 168989\n",
      "to do: 167989\n",
      "to do: 166989\n",
      "to do: 165989\n",
      "to do: 164989\n",
      "to do: 163989\n",
      "to do: 162989\n",
      "to do: 161989\n",
      "to do: 160989\n",
      "to do: 159989\n",
      "to do: 158989\n",
      "to do: 157989\n",
      "to do: 156989\n",
      "to do: 155989\n",
      "to do: 154989\n",
      "to do: 153989\n",
      "to do: 152989\n",
      "to do: 151989\n",
      "to do: 150989\n",
      "to do: 149989\n",
      "to do: 148989\n",
      "to do: 147989\n",
      "to do: 146989\n",
      "to do: 145989\n",
      "to do: 144989\n",
      "to do: 143989\n",
      "to do: 142989\n",
      "to do: 141989\n",
      "to do: 140989\n",
      "to do: 139989\n",
      "to do: 138989\n",
      "to do: 137989\n",
      "to do: 136989\n",
      "to do: 135989\n",
      "to do: 134989\n",
      "to do: 133989\n",
      "to do: 132989\n",
      "to do: 131989\n",
      "to do: 130989\n",
      "to do: 129989\n",
      "to do: 128989\n",
      "to do: 127989\n",
      "to do: 126989\n",
      "to do: 125989\n",
      "to do: 124989\n",
      "to do: 123989\n",
      "to do: 122989\n",
      "to do: 121989\n",
      "to do: 120989\n",
      "to do: 119989\n",
      "to do: 118989\n",
      "to do: 117989\n",
      "to do: 116989\n",
      "to do: 115989\n",
      "to do: 114989\n",
      "to do: 113989\n",
      "to do: 112989\n",
      "to do: 111989\n",
      "to do: 110989\n",
      "to do: 109989\n",
      "to do: 108989\n",
      "to do: 107989\n",
      "to do: 106989\n",
      "to do: 105989\n",
      "to do: 104989\n",
      "to do: 103989\n",
      "to do: 102989\n",
      "to do: 101989\n",
      "to do: 100989\n",
      "to do: 99989\n",
      "to do: 98989\n",
      "to do: 97989\n",
      "to do: 96989\n",
      "to do: 95989\n",
      "to do: 94989\n",
      "to do: 93989\n",
      "to do: 92989\n",
      "to do: 91989\n",
      "to do: 90989\n",
      "to do: 89989\n",
      "to do: 88989\n",
      "to do: 87989\n",
      "to do: 86989\n",
      "to do: 85989\n",
      "to do: 84989\n",
      "to do: 83989\n",
      "to do: 82989\n",
      "to do: 81989\n",
      "to do: 80989\n",
      "to do: 79989\n",
      "to do: 78989\n",
      "to do: 77989\n",
      "to do: 76989\n",
      "to do: 75989\n",
      "to do: 74989\n",
      "to do: 73989\n",
      "to do: 72989\n",
      "to do: 71989\n",
      "to do: 70989\n",
      "to do: 69989\n",
      "to do: 68989\n",
      "to do: 67989\n",
      "to do: 66989\n",
      "to do: 65989\n",
      "to do: 64989\n",
      "to do: 63989\n",
      "to do: 62989\n",
      "to do: 61989\n",
      "to do: 60989\n",
      "to do: 59989\n",
      "to do: 58989\n",
      "to do: 57989\n",
      "to do: 56989\n",
      "to do: 55989\n",
      "to do: 54989\n",
      "to do: 53989\n",
      "to do: 52989\n",
      "to do: 51989\n",
      "to do: 50989\n",
      "to do: 49989\n",
      "to do: 48989\n",
      "to do: 47989\n",
      "to do: 46989\n",
      "to do: 45989\n",
      "to do: 44989\n",
      "to do: 43989\n",
      "to do: 42989\n",
      "to do: 41989\n",
      "to do: 40989\n",
      "to do: 39989\n",
      "to do: 38989\n",
      "to do: 37989\n",
      "to do: 36989\n",
      "to do: 35989\n",
      "to do: 34989\n",
      "to do: 33989\n",
      "to do: 32989\n",
      "to do: 31989\n",
      "to do: 30989\n",
      "to do: 29989\n",
      "to do: 28989\n",
      "to do: 27989\n",
      "to do: 26989\n",
      "to do: 25989\n",
      "to do: 24989\n",
      "to do: 23989\n",
      "to do: 22989\n",
      "to do: 21989\n",
      "to do: 20989\n",
      "to do: 19989\n",
      "to do: 18989\n",
      "to do: 17989\n",
      "to do: 16989\n",
      "to do: 15989\n",
      "to do: 14989\n",
      "to do: 13989\n",
      "to do: 12989\n",
      "to do: 11989\n",
      "to do: 10989\n",
      "to do: 9989\n",
      "to do: 8989\n",
      "to do: 7989\n",
      "to do: 6989\n",
      "to do: 5989\n",
      "to do: 4989\n",
      "to do: 3989\n",
      "to do: 2989\n",
      "to do: 1989\n",
      "to do: 989\n",
      "to do: 0\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch.helpers as helpers\n",
    "\n",
    "label = 'esteem_title'\n",
    "query = {\n",
    "    'query': {\n",
    "        'match': {\n",
    "            'label.keyword': label\n",
    "        }\n",
    "    },\n",
    "    'track_total_hits': True,\n",
    "    'size': 1000\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "to_do = 1\n",
    "while to_do > 0:\n",
    "    response = es_republic.search(index='republic_phrase_matches', body=query)\n",
    "    clean_docs = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        match = hit['_source']\n",
    "        match['label'] = ['title' if label == 'esteem_title' else label for label in match['label']]\n",
    "        if '_score' in hit:\n",
    "            del hit['_score']\n",
    "        clean_docs.append(hit)\n",
    "    helpers.bulk(es_republic, clean_docs)\n",
    "    to_do = response['hits']['total']['value']\n",
    "    print('to do:', to_do)\n",
    "    es_republic.indices.refresh(index='republic_phrase_matches')\n",
    "#print(clean_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, [])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseMatch(phrase: \"houdende advertentie\", variant: \"houdende advertentie\",string: \"houdendeadyertentie\", offset: 155),\n",
       " PhraseMatch(phrase: \"houdende\", variant: \"houdende\",string: \"houdende\", offset: 437),\n",
       " PhraseMatch(phrase: \"houdende advertentie\", variant: \"houdende advertentie\",string: \"houdende advertentie\", offset: 437)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "\n",
    "text = 'Ntfangen een Miffive van den Heere Gallieris, haar Hoogh Mogende Minifter by den Rycksdagh , gefchree ven te Regensburgh den fesden deefer loopende maand, houdendeadyertentie, WAAR àNtfangén éen Mifive van dé SccreAO dari van den Heere Graave van Gronsfeld, haar Hoogh Mogende extraOrdinaris Envoyé en Plenipotentiaris aan het Hof van fijne Majetteyt den Koningh wan PruyfTen , gefchreeven te Berlyn den feevenden deler loopende maand , houdende advertentie. WAAR op geen refolutie is gevallen: '\n",
    "\n",
    "phrases = ['houdende', 'houdende advertentie']\n",
    "\n",
    "searcher_config = {\n",
    "    \"char_match_threshold\": 0.7,\n",
    "    \"ngram_threshold\": 0.5,\n",
    "    \"levenshtein_threshold\": 0.7,\n",
    "    \"max_length_variance\": 3,\n",
    "    \"include_variants\": True,\n",
    "    \"filter_distractors\": True,\n",
    "    \"ngram_size\": 2,\n",
    "    \"skip_size\": 2,\n",
    "}\n",
    "\n",
    "phrase_model = PhraseModel(model=phrases)\n",
    "\n",
    "temp_searcher = FuzzyPhraseSearcher(searcher_config)\n",
    "temp_searcher.index_phrase_model(phrase_model)\n",
    "\n",
    "temp_searcher.find_matches(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding phrase match scores for exact matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to do: 17634\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch.helpers as helpers\n",
    "\n",
    "phrase = 'presenteerende'\n",
    "query = {\n",
    "    'query': {\n",
    "        'match': {\n",
    "            'metadata.evidence.phrase.keyword': phrase\n",
    "        }\n",
    "    },\n",
    "    'track_total_hits': True,\n",
    "    'size': 1000\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "phrase_match_index = 'republic_phrase_matches'\n",
    "resolution_index = 'pagexml_resolutions'\n",
    "\n",
    "to_do = 1\n",
    "while to_do > 0:\n",
    "    response = es_republic.search(index=resolution_index, body=query)\n",
    "    clean_docs = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        match = hit['_source']\n",
    "        clean_docs.append(hit)\n",
    "    #helpers.bulk(es_republic, clean_docs)\n",
    "    to_do = response['hits']['total']['value']\n",
    "    print('to do:', to_do)\n",
    "    es_republic.indices.refresh(index='republic_phrase_matches')\n",
    "    break\n",
    "#print(clean_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 \t ('presenterende', 0.9285714285714286)\n",
      "15 \t ('prefenteerende', 0.9285714285714286)\n",
      "10 \t ('presenteerende', None)\n",
      "9 \t ('representeerende', 0.875)\n",
      "6 \t ('reprefenteerende', 0.8125)\n",
      "3 \t ('prefenterende', 0.8571428571428572)\n",
      "2 \t ('pracsenteerende', 0.8666666666666667)\n",
      "2 \t ('praesenteerende', 0.9333333333333333)\n",
      "2 \t ('pretendeerende', 0.8571428571428572)\n",
      "2 \t ('presen. teerende', 0.875)\n",
      "1 \t ('prelentecrende', 0.8571428571428572)\n",
      "1 \t ('tepresenteerende', 0.875)\n",
      "1 \t ('-prefenteerende', 0.8666666666666667)\n",
      "1 \t ('prefentcerende', 0.8571428571428572)\n",
      "1 \t ('nrelenteerende', 0.8571428571428572)\n",
      "1 \t ('prefenteerénde', 0.8571428571428572)\n",
      "1 \t ('pre fenteerende', 0.8666666666666667)\n",
      "1 \t ('prefenteerenAe', 0.8571428571428572)\n",
      "1 \t ('prefenteeren de', 0.8666666666666667)\n",
      "1 \t ('prefenteerënde', 0.8571428571428572)\n",
      "1 \t ('rasenteerende', 0.8571428571428572)\n",
      "1 \t ('pretenteerende', 0.9285714285714286)\n",
      "1 \t ('prelenteerende', 0.9285714285714286)\n",
      "1 \t ('reproesenteerende', 0.8235294117647058)\n",
      "1 \t (':prefenteerende', 0.8666666666666667)\n",
      "1 \t ('prefenteerene', 0.8571428571428572)\n",
      "1 \t ('Teprefenteerende', 0.8125)\n",
      "1 \t ('prelengeerende', 0.8571428571428572)\n",
      "1 \t ('repretenteerende', 0.8125)\n",
      "1 \t ('réprefenteerende', 0.8125)\n",
      "1 \t ('presenteren de', 0.8571428571428572)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import elasticsearch.helpers as helpers\n",
    "\n",
    "phrase = 'presenteerende'\n",
    "query = {\n",
    "    'query': {\n",
    "        'match': {\n",
    "            'metadata.evidence.phrase.keyword': phrase\n",
    "        }\n",
    "    },\n",
    "    'track_total_hits': True,\n",
    "    'size': 1000\n",
    "}\n",
    "\n",
    "\n",
    "count = Counter()\n",
    "\n",
    "#response = es_republic.search(index=resolution_index, body=query)\n",
    "for hit in response['hits']['hits']:\n",
    "    match = hit['_source']\n",
    "    evidence = match['metadata']['evidence']\n",
    "    for pm in evidence:\n",
    "        if pm['phrase'] != phrase:\n",
    "            continue\n",
    "        if pm['match_scores']['levenshtein_similarity'] and pm['match_scores']['levenshtein_similarity'] <= 0.8:\n",
    "            continue\n",
    "        count.update([(pm['string'], pm['match_scores']['levenshtein_similarity'])])\n",
    "\n",
    "for string, freq in count.most_common():\n",
    "    print(freq, '\\t', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2607a3b9c7b345a48fe77cff9333aba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/337 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960f52c328cf494eaedef80950345c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/220k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14216, 1508, 43, 4419, 4437, 13764, 2689, 7357, 2269, 14688, 1443, 5809, 1444, 18, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "pretrained_model_name = \"emanjavacas/GysBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "tokenized_input = tokenizer.encode(\"This is a sample text to test the tokenizer.\")\n",
    "\n",
    "print( tokenized_input )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
